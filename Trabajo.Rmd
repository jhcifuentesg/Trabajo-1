---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: yes
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: es
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.align = "center", fig.pos = "H")
library(kableExtra)
library(knitr)
library(leaps)
source("Functions.R")
library(tidyverse)
```

```{=tex}
\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\newpage
\thispagestyle{empty}
\listoffigures
\listoftables
\newpage
```

```{=tex}
\pagestyle{myheadings}
\setcounter{page}{3}
```

\section{Pregunta 1}

Teniendo en cuenta la base de datos brindada, en la cual hay 5 variables regresoras dadas por: 
$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i} + \beta_4 X_{4i} + \beta_5X_{5i}+ \varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 64$$
Donde:

\begin{itemize}
  \item Y: Riesgo de infección
  \item $X_1$: Duración de la estadía
  \item $X_2$: Rutina de cultivos
  \item $X_3$: Número de camas
  \item $X_4$: Censo promedio diario
  \item $X_5$: Número de enfermeras
\end{itemize}

```{r}
datos <- read.table("Equipo51.txt", header = T)
modelo <- lm(Y ~ ., data = datos)
betas <- round(coef(modelo), 4)
betas1 <- as.data.frame(betas)
```
\subsection{Modelo de regresión}

Al ajustar el modelo, se  obtienen los  siguientes coeficientes:

```{r}
rownames(betas1) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_5$")
betas1 %>% 
  kable(col.names = c("Valor del parámetro"), caption = "Tabla de valores coeficientes del modelo", escape = F, booktab = T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Por lo tanto, el modelo de regresión ajustado es:
$$\hat{Y}_i = -0.9267 + 0.2175 X_{1i} + 0.0144 X_{2i} + 0.0459 X_{3i} +0.0134 X_{4i} + 0.0017X_{5i} \ 1 \leqslant i \leqslant 64$$
\subsection{Significancia de la regresión}
Para analizar la significancia de la regresión, se plantea el siguiente juego de hipótesis:
$$
\begin{cases}
  \begin{aligned}
    H_0&: \beta_0 =\beta_1=\beta_2=\beta_3=\beta_4=\beta_5=0 \\
    H_1&: \text{Algún }\beta_j \text{ distinto de 0 para j=0, 1,..., 5}
  \end{aligned}
\end{cases}
$$

Cuyo estadístico de prueba es:

\begin{equation}
F_0 = \frac{MST}{MSE} \stackrel{H_0}{\sim} f_{5, `r nrow(datos)-6`}\\
\end{equation}

Ahora, se presenta la tabla Anova:
```{r}
tabla.anova <- myAnova(modelo)
rownames(tabla.anova) <- c("Regresión", "Error")
tabla.anova %>% 
  kable(col.names = c("Sumas de cuadrados", "g.l.", "Cuadrado medio", "$F_0$", "P-valor"),caption = "Tabla  ANOVA para el modelo", escape=F, booktab=T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
De la tabla Anova, se observa un valor P aproximadamente igual a 0, por lo  que se rechaza la hipótesis nula en la que $\beta_j = 0$ con $0 \leqslant j \leqslant 5$, aceptando la hipótesis alternativa en la que algún $\beta_j \neq 0$, por lo tanto la regresión es significativa. 

\subsection{Significancia  de los parámetros}
En el siguiente cuadro se presenta información de los parámetros, la cual permitirá determinar cuáles de ellos son significativos.

```{r}
tabla.coeficientes <- summary(modelo)$coefficients
rownames(tabla.coeficientes) <- paste("$\\beta_", 0:5, "$", sep = "")
tabla.coeficientes %>% 
  kable(col.names = c("$\\hat{\\beta_j}$", "$SE(\\hat{\\beta_j})$", "$T_{0j}$", "P-valor"),caption = "Resumen de los coeficientes", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Los P-valores presentes en la tabla permiten concluir que con un nivel de significancia $\alpha = 0.05$, los parámetros $\beta_1$, $\beta_3$ y $\beta_5$ son significativos, pues sus P-valores son menores a $\alpha$.

\subsection{Interpretación de los parámetros}

\textbf{$\hat{\beta_1}$: El riesgo de infeccion aumenta en 0.2175 por cada dia de de estadia cuando las demas variables predictoras se mantienen fijas}

\textbf{$\hat{\beta_3}$: El riesgo de infeccion aumenta en 0.0459 por cada cama en el hospital durante el periodo de estudio cuando las demas variables predictoras se mantienen fijas} 

\textbf{$\hat{\beta_5}$: El riesgo de infeccion aumenta en 0.0017 en relacion al numero promedio de enfermeras presentes equivalentes a tiempo completo, durante el periodo de estadia cuando las demas variables predictoras se mantienen fijas}

\subsection{Coeficiente de determinación múltiple $R^2$}

El  modelo tiene un coeficiente de determinación múltiple $R^2 = 0.6012423$, lo que significa que aproximadamente el $60.12423%$% de la variabilidad total  observada en la respuesta es explicada por el modelo de regresión propuesto en el presente informe.


\section{Pregunta 2}
\subsection{Planteamiento pruebas de hipótesis  y modelo reducido}

Las covariable con el P-valor más bajo en el modelo fueron $X_1, X_3, X_5$, por lo tanto a través de la tabla de todas las regresiones posibles se pretende hacer la siguiente prueba de hipótesis:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \beta_1 =\beta_3 = \beta_5 = 0\\
\text{H}_1&: \text{Algún } \beta_j \text{ distinto de 0 para } j=1, 3, 5
\end{aligned}
\end{cases}
$$

```{r}
todas.regresiones <- myAllRegTable(modelo)
todas.regresiones <- todas.regresiones[c(31, 14), c(4, 6)]
row.names(todas.regresiones) <- c("Modelo  completo", "Modelo reducido")
todas.regresiones %>% 
    kable(col.names = c("$SSE$", "Covariables en el modelo"), caption = "Resumen tabla de todas las regresiones", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Luego un modelo reducido para la prueba de significancia del subconjunto es:

$$Y_i = \beta_0 + \beta_2 X_{2i} + \beta_4 X_{4i} + \varepsilon; \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 64$$
\subsection{Estadístico de prueba y conclusión}
Se construye el estadístico de prueba como:

\begin{equation}
\begin{split}
F_0 &= \frac{(SSE(\beta_0, \beta_2, \beta_4) - SSE(\beta_0, \ \cdots, \ \beta_5))/3}{MSE(\beta_0, \ \cdots, \ \beta_5)} \stackrel{H_0}{\sim} f_{3, `r nrow(datos)-6`}\\
&= \frac{96.374-52.327}{0.902188} \\
&= 48.82242
\end{split}
\end{equation}

Ahora, comparando el $F_0$ con $f_{0.95, 3, `r nrow(datos)-6`} = `r round(qf(0.95, 3, nrow(datos)-6), 4)`$, se puede ver que $F_0$ > $f_{0.95, 1, 45}$, por tanto se rechaza la hipotesis nula, teniendo que al ser esto asi, no es posible descartar las variables del conjunto


\section{Pregunta 3}
\subsection{Prueba de hipótesis y prueba de hipótesis  matricial}
Se hace la pregunta si la duracion de la estadia por dia es 2 veces el numero promedio de enfermeras en tiempo completo durante el periodo del estudio y si el numero de camas promedio durante el periodo del estudio es 3 veces el numero promedio de pacientes por dia durante el periodo del estudio. Por consiguiente se plantea la siguiente prueba de hipótesis:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \beta_1 = 2\beta_5; \ \beta_3  = 3\beta_4 \\
\text{H}_1&: \text{Alguna de las igualdades no se cumple}
\end{aligned}
\end{cases}
$$

reescribiendo matricialmente:
$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \mathbf{L} \underline{\mathbf{\beta}} = \underline{\mathbf{0}} \\
\text{H}_1&: \mathbf{L} \underline{\mathbf{\beta}} \neq \underline{\mathbf{0}} \\
\end{aligned}
\end{cases}
$$

Con $\mathbf{L}$ dada por

$$
L = \begin{bmatrix}
  0 & 1 & 0 & 0 & 0 & -2\\
  0 & 0 & 0 & 1 & -3 & 0 \\
\end{bmatrix}
$$

El modelo reducido está dado por: 

$$Y_i = \beta_o  + \beta_1 X^*_{1,5i}+ \beta_2 X_{2i} + \beta_3 X^*_{3,4i}+\varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 64$$

Donde $X^*_{1,5i} = X_{1i} + 2X_{5i}$ y $X^*_{3,4i} = X_{3i} + 3X_{4i}$


\subsection{Estadístico de prueba}

El estadístico de prueba $F_0$ está dado por:

\begin{equation}
F_0 = \frac{(SSE(MR) - SSE(MF))/2}{MSE(MF)} \stackrel{H_0}{\sim} f_{2, `r nrow(datos)-6`}\\ = F_0 = \frac{(SSE(MR) -  52.327)/2}{0.902188} \stackrel{H_0}{\sim} f_{2, `r nrow(datos)-6`}\\
\end{equation}


\section{Pregunta 4}

\subsection{Supuestos del modelo}

\subsubsection{Normalidad de los residuales}

Para la validación de este supuesto, se planteará la siguiente prueba de hipótesis que se realizará por medio de shapiro-wilk, acompañada de un gráfico cuantil-cuantil:
$$
\begin{cases}
\begin{aligned}
  \text{H}_0&: \varepsilon_i \sim \text{Normal}\\
  \text{H}_1&: \varepsilon_i \nsim \text{Normal}
\end{aligned}
\end{cases}
$$
```{r fig.cap = "Gráfico cuantil-cuantil y normalidad de residuales"} 
myQQnorm(modelo, xlab = "Cuantiles teóricos",
         ylab = "Cuantiles muestrales", pch=20)
```

Al ser el P-valor aproximadamente igual a  0.5435 y teniendo en cuenta que el nivel de significancia $\alpha = 0.05$, el P-valor es mucho mayor y por lo tanto, no se rechazaría la hipótesis nula, es decir que los datos distribuyen normal con media $\mu$ y varianza $\sigma^2$, sin embargo la gráfica de comparación de cuantiles permite ver colas más pesadas y patrones irregulares, al tener más poder el análisis gráfico, se termina por rechazar el cumplimiento de este supuesto. Ahora se validará si la varianza cumple con el supuesto de ser constante.

\subsubsection{Varianza constante}

```{r fig.cap = "Gráfico residuales estudentizados vs valores ajustados"}
res.stud <- round(rstandard(modelo), 4)
yhat <- round(modelo$fitted.values, 4)
plot(yhat, res.stud, xlab = "Valores Ajustados", 
     ylab = "Residuales Estudentizados", main = "Residuales Estudentizados vs Valores Ajustados", pch=20)
abline(h = 0, lty = 2, lwd = 2, col = 2)
```

En el gráfico de residuales estudentizados vs valores ajustados se puede observar que no hay patrones en los que la varianza aumente, decrezca ni un comportamiento que permita descartar una varianza constante, al no haber evidencia suficiente en contra de este supuesto se acepta como cierto. Además es posible observar media 0.


\subsection{Verificación de las observaciones}

```{r}
Cooks.D <- round(cooks.distance(modelo), 4)
hii.value <- round(hatvalues(modelo), 4)
Dffits <- round(dffits(modelo), 4)
base.diagnostico <- data.frame(res.stud, Cooks.D, hii.value, Dffits)
```

Tengan cuidado acá, modifiquen los límites de las gráficas para que tenga sentido con lo que observan en la tabla diagnóstica. También, consideren que en aquellos puntos extremos que identifiquen deben explicar el qué causan los mismos en el modelo.

\subsubsection{Datos atípicos}

```{r fig.cap = "Identificación de datos atípicos"}
with(base.diagnostico,
     plot(res.stud, xlab="Observación", ylab = "Residuales",
          main = "Residuales estudentizados", pch = 20, ylim=c(-5, 5)))
abline(h = 3, col="red", lty = "dashed")
abline(h =- 3, col="red", lty = "dashed")
```

```{r include = F}
atipicos.criterio <- 3
base.diagnostico[base.diagnostico$res.stud > atipicos.criterio | base.diagnostico$res.stud < -atipicos.criterio, ]
```

Como se puede observar en la gráfica anterior, no hay datos atípicos en el conjunto de datos pues ningún residual estudentizado sobrepasa el criterio de $|r_{estud}| > 3$.

\subsubsection{Puntos de balanceo}

```{r fig.cap = "Identificación de puntos de balanceo"}
hii.criterio <- 2*(6/(nrow(datos)))
with(base.diagnostico,
     plot(hii.value, xlab="Observación", ylab = "Valor hii",
          main = "Gráfica de hii para las observaciones", pch = 20, ylim=c(-0.1, 0.5)))
abline(h = hii.criterio, col="red", lty = "dashed")
```

```{r}
base.diagnostico[base.diagnostico$hii.value > hii.criterio, ]
```
Al observar la gráfica de observaciones vs valores $h_{ii}$, donde la línea punteada roja representa el valor $h_{ii} = 2\frac{p}{n}$, se puede apreciar que existen 6 datos del conjunto que son puntos de balanceo según el criterio bajo el cual  $h_{ii} > 2\frac{p}{n}$, los cuales son los presentados en la tabla.

\subsubsection{Puntos  influenciales}

```{r fig.cap="Criterio distancias de Cook para puntos influenciales"}
criterio.cook <- 1
with(base.diagnostico,
     plot(Cooks.D, xlab="Observación", ylab = "Distancia de Cook",
          main = "Gráfica de distancias de Cook", pch = 20, ylim=c(-1.5, 1.5)))
abline(h = criterio.cook, col="red", lty = "dashed")
#base.diagnostico[base.diagnostico$Cooks.D > criterio.cook, ]
```

```{r fig.cap="Criterio Dffits para puntos influenciales"}
Dffits.criterio <- 2* (6/nrow(datos))^(1/2)
with(base.diagnostico,
     plot(Dffits, xlab="Observación", ylab = "Dffit",
          main = "Gráfica de observaciones vs Dffits", pch = 20, ylim=c(-2.1, 1.5)))
abline(h = Dffits.criterio, col="red", lty = "dashed")
abline(h = -Dffits.criterio, col="red", lty = "dashed")
base.diagnostico[base.diagnostico$Dffits > Dffits.criterio | base.diagnostico$Dffits < -Dffits.criterio, ]
```
Como se puede ver,las observaciones 6, 33, 58, 61, y 64 son puntos influenciales según el criterio de Dffits, el cual dice que para cualquier punto cuyo $|D_{ffit}| > 2\sqrt{\frac{p}{n}}$, es un punto influencial. Cabe destacar también que con el criterio de distancias de Cook, en el cual para cualquier punto cuya $D_{i} > 1$, es un punto influencial, ninguno de los datos cumple con serlo.

\subsection{Conclusión}

Dado que el P-Valor obtenido en la tabla ANOVA es de 1.58805e-10, podemos afirmar que el modelo funciona para cualquier alfa. 

evaluando las observaciones de influencia con los diagnosdicadores Cook y DFFITS concluimos que ninguna de las observaciones son significativas.






